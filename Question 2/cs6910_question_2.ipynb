{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2:\n",
        "\n",
        "Implement a feedforward neural network which takes images from the fashion-mnist data as input and outputs a probability distribution over the 10 classes.\n",
        "\n",
        "Your code should be flexible such that it is easy to change the number of hidden layers and the number of neurons in each hidden layer."
      ],
      "metadata": {
        "id": "R4ULXAST2hLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the FASHION-MNIST dataset**\n",
        "\n",
        "Furthermore, the data is segreggated into training and test data"
      ],
      "metadata": {
        "id": "KilU0eW09lzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "X_train,Y_train = train_images.reshape(train_images.shape[0], -1).T/225,train_labels\n",
        "X_test,Y_test = test_images.reshape(test_images.shape[0], -1).T/225,test_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65TM9UYH9iBO",
        "outputId": "6c9f3559-8ef6-419e-ef75-42e1ce2d0099"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing a few functions that we have defined, for example, activation functions, intializers etc.**"
      ],
      "metadata": {
        "id": "cYoK3QZ0_UML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from initializers import init_params, xavier_init_params\n",
        "from activation_functions import ReLU,sigmoid,tanh,softmax,softmax_mod"
      ],
      "metadata": {
        "id": "dcZ5C7D5EDAW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The function performs the forward propagation.**\n",
        "\n",
        "It takes the parameter set 'params', the vectorized pixel values 'X' and the type of activation funtion 'act' and retuns the activated outputs of all the neurons in the neural network as a dictionary."
      ],
      "metadata": {
        "id": "C5rq7KYD_0-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Forward propagation:\n",
        "def forward_prop(params, X, act):\n",
        "    num_layers = len(params)//2\n",
        "    activations = {}\n",
        "    activations['h0'] = X\n",
        "\n",
        "    for i in range(1, num_layers): #hidden layers\n",
        "        Wi = params[f'W{i}']\n",
        "        bi = params[f'b{i}']\n",
        "        ai = np.dot(Wi, activations[f'h{i-1}']) + bi\n",
        "        if act=='sigmoid':\n",
        "          hi = sigmoid(ai)\n",
        "        elif act=='tanh':\n",
        "          hi = tanh(ai)\n",
        "        elif act=='relu':\n",
        "          hi = ReLU(ai)\n",
        "\n",
        "        activations[f'a{i}'] = ai\n",
        "        activations[f'h{i}'] = hi\n",
        "\n",
        "    W_last = params[f'W{num_layers}'] #last layer\n",
        "    b_last = params[f'b{num_layers}']\n",
        "    a_last = np.dot(W_last, activations[f'h{num_layers-1}']) + b_last\n",
        "    h_last = softmax_mod(a_last)\n",
        "    activations[f'a{num_layers}'] = a_last\n",
        "    activations[f'h{num_layers}'] = h_last\n",
        "\n",
        "    return activations"
      ],
      "metadata": {
        "id": "lbOg1w6h_woG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's try out the forward propagation code**"
      ],
      "metadata": {
        "id": "wZKszfXLAQaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_hidden_layers=4\n",
        "size_of_hidden_layer=32\n",
        "activation='relu' #sigmoid,tanh,relu\n",
        "input_size,output_size = 784,10\n",
        "layer_sizes = [input_size] + [size_of_hidden_layer] * no_hidden_layers + [output_size]\n",
        "print(\"Layer architecture: \",layer_sizes)\n",
        "params=xavier_init_params(layer_sizes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bD9DWRKXAL7E",
        "outputId": "ee48a8c0-f2b9-4c84-de76-1a8dec746430"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer architecture:  [784, 32, 32, 32, 32, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Taking a simple input from the training data-set\n",
        "sample_input=X_train[:,10].reshape(-1,1)\n",
        "#Running the forward pass to store the activated values of all the neurons\n",
        "forward_activations=forward_prop(params, sample_input, activation)\n",
        "\n",
        "num_layers = len(params) // 2\n",
        "output = forward_prop(params, sample_input, activation)\n",
        "print(\"Output of the neural-network:\\n\", output[f'h{no_hidden_layers + 1}'])\n",
        "print(\"Sum of of the outputs: \",np.sum(output[f'h{no_hidden_layers + 1}']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52e9uVjTA7di",
        "outputId": "146cc2f8-3886-484b-8353-b095f1ae9a2e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output of the neural-network:\n",
            " [[0.0903115 ]\n",
            " [0.10491488]\n",
            " [0.09904978]\n",
            " [0.10253558]\n",
            " [0.08582992]\n",
            " [0.09861023]\n",
            " [0.1032042 ]\n",
            " [0.08547898]\n",
            " [0.10864541]\n",
            " [0.12141952]]\n",
            "Sum of of the outputs:  1.0\n"
          ]
        }
      ]
    }
  ]
}